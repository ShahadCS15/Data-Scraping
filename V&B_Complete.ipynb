{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests import exceptions\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "    try:\n",
    "        r = requests.get(url, verify=False)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        return soup\n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specs(soup):\n",
    "    try:\n",
    "        body = soup.find(\"table\",{\"class\":\"product_detail_techinfo\"}).find_all('tr')\n",
    "        inner_dictionary = {}\n",
    "\n",
    "        for row in body:\n",
    "            cols = row.findChildren(recursive=False)\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            inner_dictionary.update({cols[0] : cols[1]})\n",
    "        return inner_dictionary\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AllPDF(soup):\n",
    "    try:\n",
    "        h3_lst = soup.findAll('h3', {'class' : 'product_detail_download_list_headline'})\n",
    "        header_lst = []\n",
    "        for h3 in h3_lst:\n",
    "            #print(h3.text)\n",
    "            header_lst.append(h3.text.strip('\\n\\t').strip())\n",
    "            h3.find_next('h3')\n",
    "        #print(header_lst)\n",
    "        \n",
    "    \n",
    "        a_lst = soup.findAll('a', {'class' : 'product_detail_download_list_item'})\n",
    "        pdf_lst = []\n",
    "        \n",
    "        for pdf in a_lst:\n",
    "            pdf_link = pdf.get('href')\n",
    "            pdf_link = 'https://www.villeroy-boch.asia/' + pdf_link\n",
    "            pdf_lst.append(pdf_link)\n",
    "            pdf.find_next('a')\n",
    "        #print(pdf_lst)\n",
    "            \n",
    "        pdf_dic = {}\n",
    "\n",
    "        for i in range(len(header_lst)):\n",
    "            pdf_dic.update({header_lst[i] : pdf_lst[i]})\n",
    "        return pdf_dic\n",
    "    \n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_driver(item_id):\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    #driver = webdriver.Chrome('C:\\\\Users\\\\Shahad\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe')\n",
    "    options.headless = True\n",
    "    driver = webdriver.Chrome('C:\\\\Users\\\\Shahad\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe', options=options)  \n",
    "        \n",
    "    driver.get('https://www.villeroy-boch.asia/en/?_ga=GA1.2.1733028649.1542622446')\n",
    "\n",
    "    print(item_id)\n",
    "    try:\n",
    "        popup_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll'))\n",
    "        )\n",
    "        popup_btn.click()\n",
    "\n",
    "\n",
    "        search_icon = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'icon-search'))\n",
    "        )\n",
    "        search_icon.click()\n",
    "\n",
    "        search_bar = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.ID, 'search-form-input'))\n",
    "        )\n",
    "        search_bar.send_keys(item_id)\n",
    "\n",
    "        search_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'epoq_search_button'))\n",
    "        )\n",
    "        search_btn.click()\n",
    "\n",
    "        select_item = driver.find_element_by_xpath(\"//div[@class='epoq_resultrow epoq_grid']/a\")\n",
    "        item_url = select_item.get_attribute('href')\n",
    "        return item_url\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'V&B_draft1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURLs():\n",
    "    url_lst = []\n",
    "    for i in df.index:\n",
    "        item_url = page_driver(str(df['Item Code'][i]))\n",
    "        url_lst.append(item_url)\n",
    "    return url_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(soup):\n",
    "    try:\n",
    "        img_dic = {}\n",
    "        num=1\n",
    "        img_base_link = 'https://www.villeroy-boch.asia/'\n",
    "        images = soup.findAll('img', {'alt' : 'Artis Surface-mounted washbasin'})\n",
    "        for i in images:\n",
    "            #img = i.get('src')\n",
    "            img_dic.update({'image_'+str(num) : img_base_link + i.get('src')})\n",
    "            num+=1\n",
    "        return img_dic\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_img(soup):\n",
    "    try:\n",
    "        all_colors = soup.findAll('a', {'class' : 'colorchange'})\n",
    "        color_img = []\n",
    "        color_base_link = 'https://www.villeroy-boch.asia/'\n",
    "        for i in all_colors:\n",
    "            img = color_base_link + i.get('data-colorfile')\n",
    "            color_img.append(img)\n",
    "        \n",
    "    \n",
    "        all__titles = soup.findAll('img', {'class' : 'product_detail_color_img'})\n",
    "        title_img = []\n",
    "        for i in all__titles:\n",
    "            title = i.get('title')\n",
    "            title_img.append(title)\n",
    "            \n",
    "        color_img_dic = {}\n",
    "        for i in range(len(title_img)):\n",
    "            color_img_dic.update({title_img[i] : color_img[i]})\n",
    "\n",
    "        return color_img_dic\n",
    "    \n",
    "    except:\n",
    "        try:\n",
    "            color_img = []\n",
    "            color_img_dic = {}\n",
    "            #if not color_img_dic:\n",
    "            div = soup.findAll('div', {'class' : 'product_detail_slider_item'})\n",
    "            for i in div:\n",
    "                img = color_base_link + i.find_next('img').get('src')\n",
    "                color_img.append(img)\n",
    "\n",
    "            for i in range(len(color_img)):\n",
    "                color_img_dic.update({'image_'+str(i+1) : color_img[i]})\n",
    "            return color_img_dic\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = getURLs()\n",
    "df['webpage_to_be_scraped'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soup'] = df['webpage_to_be_scraped'].apply(lambda x:create_soup(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['img'] = df['soup'].apply(lambda x:get_colors_img(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df['img'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df, df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['All_PDF'] = df['soup'].apply(lambda x:get_AllPDF(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df['All_PDF'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df, df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['specs'] =  df_merged['soup'].apply(lambda x:get_specs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_merged['specs'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_merged, df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('V&B_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
